
import json
import os
import pandas as pd
import time
from datetime import datetime
from os.path import join

df = pd.DataFrame([], columns=['URL','SEO','Accessibility','Performance','Best Practices'])
name = "RocketClicks" 
getdate = datetime.now().strftime("%m-%d-%y")
relative_path = 'C:\\Users\\mlope\\OneDrive\\Documentos\\Lighthouse\\Lighthouse_working\\assets\\'  ### WINDOWS -> \\..\\..\\


urls = [
"https://arctictravelcompany.com/",
"http://www.fjellheisen.no"
]

def extract_info(preset):
    global df
    for url in urls:        
        stream = os.popen('lighthouse --disable-storage-reset=true --preset=' +
                          preset + ' --output=json --output-path='+relative_path + name+'_'+getdate+'.report.json ' + url)

        time.sleep(60)
        print("Report complete for: " + url)

        json_filename = join(relative_path+name+ '_' +getdate + '.report.json ')

        with open(json_filename, encoding="utf8") as json_data:
            loaded_json = json.load(json_data)

        seo = str(round(loaded_json["categories"]["seo"]["score"] * 100))
        accessibility = str(round(loaded_json["categories"]["accessibility"]["score"] * 100))
        performance = str(round(loaded_json["categories"]["performance"]["score"] * 100))
        best_practices = str(round(loaded_json["categories"]["best-practices"]["score"] * 100))

        dict = {"URL":url,"SEO":seo,"Accessibility":accessibility,"Performance":performance,"Best Practices":best_practices}
        df = df.append(dict, ignore_index=True).sort_values(by='SEO', ascending=False)

df.to_csv(relative_path + name + '_' + getdate + '.csv')
print(df)

extract_info(preset='desktop')